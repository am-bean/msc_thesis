{"episode_reward_max": 12.0, "episode_reward_min": 12.0, "episode_reward_mean": 12.0, "episode_len_mean": 24.0, "episode_media": {}, "episodes_this_iter": 42, "policy_reward_min": {"player_0": 1.0, "player_1": 0.0, "player_2": 1.0, "player_3": 0.0}, "policy_reward_max": {"player_0": 6.0, "player_1": 5.0, "player_2": 6.0, "player_3": 5.0}, "policy_reward_mean": {"player_0": 3.1904761904761907, "player_1": 2.8095238095238093, "player_2": 3.1904761904761907, "player_3": 2.8095238095238093}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0], "episode_lengths": [24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24], "policy_player_0_reward": [3.0, 1.0, 4.0, 3.0, 3.0, 5.0, 2.0, 5.0, 5.0, 2.0, 3.0, 6.0, 2.0, 4.0, 6.0, 3.0, 2.0, 1.0, 6.0, 3.0, 5.0, 3.0, 1.0, 4.0, 1.0, 3.0, 3.0, 3.0, 5.0, 2.0, 6.0, 2.0, 2.0, 3.0, 2.0, 3.0, 4.0, 2.0, 4.0, 3.0, 2.0, 2.0], "policy_player_1_reward": [3.0, 5.0, 2.0, 3.0, 3.0, 1.0, 4.0, 1.0, 1.0, 4.0, 3.0, 0.0, 4.0, 2.0, 0.0, 3.0, 4.0, 5.0, 0.0, 3.0, 1.0, 3.0, 5.0, 2.0, 5.0, 3.0, 3.0, 3.0, 1.0, 4.0, 0.0, 4.0, 4.0, 3.0, 4.0, 3.0, 2.0, 4.0, 2.0, 3.0, 4.0, 4.0], "policy_player_2_reward": [3.0, 1.0, 4.0, 3.0, 3.0, 5.0, 2.0, 5.0, 5.0, 2.0, 3.0, 6.0, 2.0, 4.0, 6.0, 3.0, 2.0, 1.0, 6.0, 3.0, 5.0, 3.0, 1.0, 4.0, 1.0, 3.0, 3.0, 3.0, 5.0, 2.0, 6.0, 2.0, 2.0, 3.0, 2.0, 3.0, 4.0, 2.0, 4.0, 3.0, 2.0, 2.0], "policy_player_3_reward": [3.0, 5.0, 2.0, 3.0, 3.0, 1.0, 4.0, 1.0, 1.0, 4.0, 3.0, 0.0, 4.0, 2.0, 0.0, 3.0, 4.0, 5.0, 0.0, 3.0, 1.0, 3.0, 5.0, 2.0, 5.0, 3.0, 3.0, 3.0, 1.0, 4.0, 0.0, 4.0, 4.0, 3.0, 4.0, 3.0, 2.0, 4.0, 2.0, 3.0, 4.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1377316810241759, "mean_inference_ms": 0.30619717484940284, "mean_action_processing_ms": 0.030550036677884543, "mean_env_wait_ms": 0.12236757680087787, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1020, "timesteps_this_iter": 200, "agent_timesteps_total": 1017, "timers": {"learn_time_ms": 46.877, "learn_throughput": 4266.515, "update_time_ms": 0.0}, "info": {"learner": {"player_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.11328853666782379, "mean_q": -4.6481731260428205e-05, "min_q": -0.0035275721456855536, "max_q": 0.004009943455457687, "cur_lr": 0.001}, "td_error": [0.0015816889936104417, -0.0012365813599899411, -5.996264934539795, -3.997903823852539, -0.0018767383880913258, 0.0008220289601013064, -0.0013783868635073304, 0.00011176173575222492, -3.0009491443634033, -0.0018767383880913258, 0.0018112246179953218, -0.001299297553487122, 0.0002896134974434972, 0.0021458701230585575, -0.0036570029333233833, 0.0003016834962181747, -0.0026773004792630672, -1.9991520643234253, -5.003527641296387, -3.0021555423736572, -0.0013783868635073304, -3.0021555423736572, 0.0018009552732110023, -0.0017191835213452578, -0.0013783868635073304, -0.0014477729564532638, -0.0014477729564532638, -0.0017106388695538044, -0.003267933614552021, -6.000051498413086, -3.0001189708709717, -0.0017106388695538044, 0.000579155283048749, -3.997903823852539, 0.0013508083065971732, -0.0012365813599899411, -3.0034303665161133, 7.9774996265769e-05, 0.0006355458172038198, -0.00017069815658032894, -0.003267933614552021, -0.00046290754107758403, 0.0013476029271259904, 0.0018560142489150167, -0.0006559988833032548, -3.888062201440334e-05, 0.005456832237541676, -0.0011691504623740911, -0.00021844531875103712, -0.0016047912649810314, 0.005456832237541676, 0.00025541489594615996, -0.0017106388695538044, 0.0005968485493212938, -1.9991520643234253, -0.0005859574303030968, -1.0013808012008667, 0.000838344101794064, -0.0018349947640672326, -0.002985745668411255, -0.000619188416749239, 0.003579440526664257, -0.0018349947640672326, 0.0009716678177937865, 0.001873950008302927, -0.003613277105614543, -0.002556336112320423, -0.004220000933855772, -0.0035840871278196573, -0.005105631425976753, -0.0016047912649810314, 0.0005654968554154038, 0.0011694261338561773, -3.0034303665161133, -2.0003349781036377, 0.004458860494196415, -0.0030172383412718773, -0.002400094410404563, -0.0022904190700501204, 0.0011774194426834583, -1.9980278015136719, -0.002124595921486616, -0.0035840871278196573, 0.0013476029271259904, 0.005213768221437931, 0.0014160110149532557, -0.003354085609316826, 0.0013508083065971732, 0.0015816889936104417, -0.004342643078416586, -0.0018402445130050182, -3.0006165504455566, -0.0026773004792630672, -0.0033153623808175325, 0.0013317844131961465, 0.0001028874539770186, 0.002595220459625125, 0.0010284980526193976, -0.0010985753033310175, -0.0020427575800567865, -0.002645811066031456, 0.002693951828405261, -0.00033042230643332005, -0.005940520204603672, -0.001826970255933702, 0.0030592400580644608, 0.001788121066056192, -3.0016095638275146, 0.007086043246090412, 0.0008745042723603547, -0.0014685137430205941, 0.002491234103217721, -3.99686861038208, 0.0011630116496235132, -0.0026128264144062996, -2.999659538269043, -0.00021844531875103712, -0.00046290754107758403, -0.0011027331929653883, -3.99686861038208, 0.001847958890721202, -0.0010184705024585128, -2.9997594356536865, -0.0033153623808175325, 0.0023779349867254496, 0.0002896134974434972, -0.004470132291316986, -0.002124595921486616, -0.0026983791030943394, 0.0024281409569084644, 0.004458860494196415, -2.0031070709228516, -0.0008973804069682956, -3.888062201440334e-05, -0.0018402445130050182, -0.0011691504623740911, -0.0012590981787070632, 0.0001028874539770186, 0.0018560142489150167, -0.00021844531875103712, -0.0005859574303030968, -0.0017191835213452578, 0.0024281409569084644, -0.002945897402241826, -0.0026983791030943394, -0.005955549422651529, -0.0012033300008624792, -0.0018602731870487332, -0.00025664447457529604, -0.0011027331929653883, 0.001788121066056192, -4.998075485229492, -0.0018242732621729374, -0.0012449008645489812, -0.0010184705024585128, -1.0028557777404785, 0.0024281409569084644, -2.0018222332000732, 0.0023014401085674763, -0.0005181725136935711, 0.0022922479547560215, -0.0011332733556628227, -0.0005308695835992694, -0.0005859574303030968, -0.0006559988833032548, 7.9774996265769e-05, 0.0015816889936104417, 0.004458860494196415, 0.002693951828405261, 0.0018009552732110023, -0.0016905383672565222, -0.0008372144075110555, 0.0023779349867254496, 0.0010284980526193976, -0.004696942400187254, -0.0013949353015050292, -0.0030172383412718773, -2.9990246295928955, -0.002326146699488163, -0.002124595921486616, 0.0010284980526193976, 0.0001028874539770186, -0.0036570029333233833, -0.005955549422651529, -0.0021754377521574497, -0.0003953372361138463, -4.0009541511535645, -0.000942938553635031, -0.0018242732621729374, -0.0024300534278154373, 0.000838344101794064, -2.9990246295928955, -0.0009889693465083838, -2.0003349781036377, -3.0032267570495605, -0.0018402445130050182, -0.002326146699488163, 0.0011774194426834583, -0.000837214756757021, -0.001156509737484157], "mean_td_error": -0.485465407371521, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1020, "num_agent_steps_sampled": 1017, "num_steps_trained": 200, "num_steps_trained_this_iter": 200, "num_agent_steps_trained": 800, "last_target_update_ts": 1020, "num_target_updates": 1}, "done": true, "episodes_total": 42, "training_iteration": 1, "trial_id": "59acf_00000", "experiment_id": "50d8be602fe7405bb0655c90e614cb3b", "date": "2022-07-06_15-31-48", "timestamp": 1657117908, "time_this_iter_s": 1.0156152248382568, "time_total_s": 1.0156152248382568, "pid": 47176, "hostname": "AndrewXPS15", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 30, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 200, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 200, "soft_horizon": false, "no_done_at_end": false, "env": "cards", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 30, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 200, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 200, "soft_horizon": false, "no_done_at_end": false, "env": "cards", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"player_0": ["<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>", "Dict(action_mask:MultiBinary(24), observation:MultiBinary((25, 24)))", "Discrete(24)", {"model": {"custom_model": "masked_dqn"}}], "player_1": ["<class 'dqn_agents.mask_dqn_model.MaskedRandomPolicy'>", "Dict(action_mask:MultiBinary(24), observation:MultiBinary((25, 24)))", "Discrete(24)", {}], "player_2": ["<class 'dqn_agents.mask_dqn_model.MaskedRandomPolicy'>", "Dict(action_mask:MultiBinary(24), observation:MultiBinary((25, 24)))", "Discrete(24)", {}], "player_3": ["<class 'dqn_agents.mask_dqn_model.MaskedRandomPolicy'>", "Dict(action_mask:MultiBinary(24), observation:MultiBinary((25, 24)))", "Discrete(24)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x0000022A31020430>", "policies_to_train": ["player_0"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"player_0": ["<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>", "Dict(action_mask:MultiBinary(24), observation:MultiBinary((25, 24)))", "Discrete(24)", {"model": {"custom_model": "masked_dqn"}}], "player_1": ["<class 'dqn_agents.mask_dqn_model.MaskedRandomPolicy'>", "Dict(action_mask:MultiBinary(24), observation:MultiBinary((25, 24)))", "Discrete(24)", {}], "player_2": ["<class 'dqn_agents.mask_dqn_model.MaskedRandomPolicy'>", "Dict(action_mask:MultiBinary(24), observation:MultiBinary((25, 24)))", "Discrete(24)", {}], "player_3": ["<class 'dqn_agents.mask_dqn_model.MaskedRandomPolicy'>", "Dict(action_mask:MultiBinary(24), observation:MultiBinary((25, 24)))", "Discrete(24)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x0000022A31020430>", "policies_to_train": ["player_0"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1.0156152248382568, "timesteps_since_restore": 200, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 12.05, "ram_util_percent": 69.94999999999999}}
